---
layout:     post
title:      舆情平台之 千万级实时文本去重
subtitle:   算法工程结合求解之路
date:       2018-03-2
author:     BitLines
header-img: img/post-bg-blog.jpeg
catalog: true
tags:
    - 机器学习
    - 自然语言处理
---

# 舆情平台之千万级实时文本去重

文本去重技术是舆情分析的利器，是舆情系统和搜索引擎至关重要的一个模块。

## 背景

舆情平台的一项基本产品功能是用户指定关键词，来查看与关键词相关的文章。在一段时间内，某个事件会成为热门话题，不同媒体站点都可能会针对该事件进行响应，包括编写原创、转载文章、引用文章、借鉴文章、甚至盗窃文章，因此针对该事件互联网的各个媒体站点上会有大量文章进行描述。由于存在互相转载和借鉴的现象，描述该事件的很多文章都是相似的。针对这个事件的文章，用户在舆情平台上浏览时，有两个需求点：

>1. 在文章列表页，希望看到**多样性**的文章，而不是相似或者相同的文章。同时对每篇文章，要计算出与其**相似的文章数量**，并且可以按照相似文章数量进行升序或降续排序。
>2. 在文章详情页，希望看到本篇文章的内容，同时可以查看**哪些其他媒体发布了类似的文章**，以及跳转到其他相似文章的详情页来进一步浏览。

对上述两个需求进行分析，可以总结出需要解决的两个问题：

>1. 问题1：需求 1） 需要对相似的文章去重，并且可以统计相似文章的数量；
>2. 问题2：需求 2） 需要给定一篇文章，检索出与其相似的其他文章。

在数据量小的情形下，这个两个问题根本不是问题（全库扫描就可以把问题轻松解决）。然而舆情平台每天文章的入库量就有上百万之多，累积1个月量级轻轻松松上千万！如何在千万量级的背景下，解决这两个问题，还是很具有挑战性的。

## 解决之道 - 算法幽探

调研过**文本去重**技术方案的小伙伴，一定第一时间想到的方法就是**局部敏感哈希**（Locality-Sensitive Hashing, LSH）。没错，我们采取的技术方案就是基于局部敏感哈希的一种 **simhash** 来完成的。然而只简单采用 simhash 并不能完全解决上面两个问题。为什么不能呢？别急让我先给不了解 simhash 的小伙伴科普一下 simhash， 然后再回答这个问题。

### 局部敏感哈希之 simhash

业界很具有影响力也是使用广泛的大规模相似文章去重的方法是Simhash。早在 2007 年，Simhash 就由 google 工程师 Manku 等在论文 [《Detecting Near-Duplicates for Web Crawling》](http://www2007.org/papers/paper215.pdf) 提了出来，用来解决网络爬虫网页去重的问题。Simhash 实际上一种字符串散列值的计算方法，把一个任意长度的字符串映射为一个64位的整数。其特点是特征相似的字符串计算出的散列值的海明距离较小。对于给定的两篇文章，如果这两篇文章通过simahsh计算出的散列值的海明距离小于等于3，则认为这两篇文章相似。
具体simhash散列值计算步骤为：

>- 1）首先将文章转换为一组特征权重对集合 ${(feature, weight)}$，其中 $feature$ 是特征，$weight$ 是其权重。（一般情况下， $feature$ 是文章中的词，$weight$ 是词出现的频次）。
>- 2）初始化一个 64 维的整数数组 $V$，数组中每一个元素初始值为 0。
>- 3）遍历特征集合中的每一个特征权重对，a)利用哈希函数映射 $feature$ 到一个64位的散列值；b)对这个64位的散列值，如果第i比特位上为1，对数组 $V$ 中第 $i$ 个元素加上这个特征的权值$weight$，否则减去特征的权值 $weight$。
>- 4）根据数组 $V$ 中每一个元素的正负符号来确定最终生成的64位散列值，如果数组 $V$ 的第 $i$ 个元素的符号为正，则对应的散列值的第i比特位为1，否则为0。

如果使用有序表来存储 simhash 计算出的散列值，那么增加和删除的时间复杂度都是 $O(log(n))$ 。而查找相似文章（查找是否存在其他海明距离小于等于3的散列值）的时间复杂度是 $O(n)$。$O(n)$  的时间复杂度对于千万量级的文章数来说显然是不可忍受的。不过 simhash 可以通过鸽巢原理来极大降低查询的复杂度。

**鸽巢原理**：如果两个simhash散列值的海明距离小于 $k$ ，把64位 simhash 散列值分割成 $k+1$ 组。那么这两个散列值的 $k+1$ 组中，至少存在1组是相等的。

通过鸽巢原理，可以极大程度的降低查找相似文章的时间复杂度。具体方法是 ：

- **在添加 simhash 散列值时**，首先对 simhash 散列值进行分组，然后以每一个分组作为键值分别做一个索引存储；

- **在查找相似 simhash 散列值时**，首先还是对 simhash 散列值进行分组，然后用每个组分别去对应的索引中查询，最后在把所有组的查询结果合并。这样查找的复杂度可以下降 $2^m/(m * (k+1))$ 倍，其中$m$ 是每个分组中的比特位数，$k$ 是认为文章相似的最大海明距离。

>**注解**：这里这么讲解添加和查找的方法可能不太直观，不少同学都表示没有懂。确实我的描述不是特别清楚。为了让大家搞明白这里，我用大白话举个“栗子”吧！
> - **在添加时**，假如我们有一个 64 比特位的 simhash 散列值 $H_1$，我们首先分成4段，每段 16 比特位。也就是把 $H_1$ 分段变为 $A_1 B_1 C_1 D_1$。然后我们要有 4 个map（python 里面叫dict），$MapA$ 对应 $A_1$， $MapB$ 对应 $B_1$，$MapC$ 对应 $C_1$，$MapD$ 对应 $D_1$。然后分别以 $(A_1, H_1)$、$(B_1, H_1)$、$(C_1, H_1)$、$(D_1, H_1)$ 作为键值队把其存入对应的 Map 中。相当对于对每段分别做了独立索引存储。所需要的内存和插入时间都变为 4 倍。
 > - **在查找时**，同样假如我们有一个 64 比特位的 simhash 散列值 $H_2$，我们还是首先分成4段（分割方式和添加时是一样的），每段 16 比特位。也就是把 $H_2$ 分段变为 $A_2 B_2 C_2 D_2$。然后我们要去 4 个 map 中分别进行一次查找，$MapA$ 对应 $A_2$， $MapB$ 对应 $B_2$，$MapC$ 对应 $C_2$，$MapD$ 对应 $D_2$。我们有了 4 份查找结果，最后需要对这 4 份查找结果先取并集然后去重，就得到了最终查找结果。

> 这里使用 map 来举例子只是帮助大家理解，而在实际工程实现的时候并不会真正用 map 这个数据结构。 想了解具体实现的小伙伴可以联系我，我给你看源代码。
 
当 $k$ 取 3 的时候，$m = 64 / (3 + 1) = 16$，查找的时间复杂度就会下降 $2^16/((3+1)*16) =  1024$ 倍，如果进行二级索引，查找的时间复杂度会下降  $2^16/((3+1)*16) * 2^12/((3+1)*12) = 87381.33$  倍 ！如何构建索引以及多级索引见下图

![image](https://user-images.githubusercontent.com/80689631/112104407-20905180-8be6-11eb-80e9-0cb6dbb2e6c6.png)


好了，到此为止 simhash 的基本原理已经介绍完毕，我们再回头看看为什么 simhash 不能完美的解决（不是不能解决，而是不能顺畅的解决，硬着头皮去解决肯定难受的很）文章开篇我提出的两个问题。

虽然 simhash 能快速查找相似的散列值，但是这还并没有真正解决这两个问题。

**先从理论的角度出发**，

> - 对于问题1），肯定会出现两篇文章的 simhash 散列值完全相等的情况，因此不同的散列值数量并不是实际不同文章的数据。要计算相似文章数据，需要维护一个散列值映射文章数量的数据结构，在查找的过程中把文章数量累加；
> - 对于问题2），simhash 查找只能返回散列值而不是文章本身。想要得到文章，需要建立散列值到文章的倒排索引。在查找的过程中，要先查找出相似的散列值列表，然后遍历该列表检索出所有的文章。这样存在的问题是，有多少篇相似的文章就好检索多少次，性能存在很大的问题。

**再从实际情况来看**，在舆情平台的系统场景，文章是存储在搜索引擎中的。这样的话，
> 搜索引擎提供的基础功能是倒排检索和条件过滤，存储的记录是文章而不是 simhash 散列值，没有直接的方法来维护 simhash 散列值到文章数量索引，也没有直接的方法来实现上面介绍的基于鸽巢原理的查找方案。


### 等价类 之 双亲森林

有什么更好的方案呢？这两个问题很棘手的根本原因是 simhash 的计算方法不能使相似的文章得到相等的散列值，而只是使相似文章之间散列值的海明距离较小。如果相似文章的散列值相等，那么这两个问题都迎刃而解。具体的，
> 对于问题1），只要建立文章散列值的正排索引，在通过倒排检索出文章之后，通过散列值对文章进行去重，并计算出重复数量即可；  
> 对于问题2），只要建立文章散列值的倒排索引，可以通过散列值来检索出与本文章相似的其他文章。

现在，我们的问题就转变为“**如何使相似的文章的散列值相等？**”。这个问题的用数据模型来描述是集合的等价类划分问题。

**等价类**：等价关系是指定义在集合$A$上的关系，满足自反的、对称的和传递的等性质。设$R$是定义在集合$A$上的等价关系，与$A$中一个元素$a$有关系的所有元素的集合叫做$a$的等价类。

现在我们只要把所有文章集合，划分等价类。对某个等价类中的任意一篇文章，在该等价类中都存在一篇其他文章与其相似,，并且两两文章之间是相似可达的。

构造等价类，需要借助数据结构**双亲森林**，此森林要满足的条件：

>- 1）森林中所有树的高度小于等于2；
>- 2）树根代表整棵树作为文章最终的散列值，叶子表示文章的 simhash 散列值，每个 simhash 散列值在森林中有且只有1个点与其对应（或者树根或者叶子）；
>- 3）树根与树根之间的 simhash 散列值的海明距离大于3
>- 4）对每个叶子，至少存在一个兄弟节点或者树根与其的海明距离小于等于3。

森林如图所示，

![image](https://user-images.githubusercontent.com/80689631/112104764-90064100-8be6-11eb-8dbd-0e302dcda64b.png)

基于这个双亲森林，森林中的每棵树代表一个等价类，树根作为等价类的代表。

这个等价类的构造过程为：
>- 1）通过simhash方法计算文章的散列值，
>- 2）对于这个simhash散列值，若
>    - a) 该simhash散列值与其他所有节点的海明距离大于3，则向此森林中添加一棵树，以此simhash散列值作为树根，返回树根的simhash散列值；
>    - b) 存在其他simhash散列值与其海明距离小于等于3，则找出所有这些simhash散列值的根节点，如果这个根节点唯一，则把该simhash散列值添加到该根节点的孩子中，返回树根的simhash散列值；
>- 3）如果上述2）中查找的树根不唯一，则使用冲突解决办法
>    - a) 选取孩子数量最多的树根
>    - b) 如果有多个树根的节点数量相同，选取添加时间最早的树根
>    - c) 如果添加时间仍然相同，选择散列值较小的树根。

此过程如图所示，

![image](https://user-images.githubusercontent.com/80689631/112104881-ae6c3c80-8be6-11eb-9de6-5c067ce69948.png)


此外，通过浏览相似文章，我们发现一些相似的文章中绝大多数段落描述的内容都是一样的，而个别段落会加上文章编辑的少量的修改。这样的两篇文章计算出的simhash散列值的海明距离是大于3的。为了解决这个问题，我们对计算simhash散列值时的特征选择进行了优化。优化的方法是选择文章中最长的一句话代表整篇文章，而不是把整篇文章全部计算在内，这样就避免了个别段落内容不同导致文章计算出的simhash散列值的海明距离较大。

最终处理流程如下图，


![image](https://user-images.githubusercontent.com/80689631/112105975-08213680-8be8-11eb-99a5-f0ed9d514f8d.png)


### 过期数据清理

随着数据的积累，simhash 表和双亲森林都会变得越来越庞大，占用内存越来越高，因此对于时间太久的数据需要定期对其删除。为了不影响树结构的变化，需要让树根的生命周期大于等于所有叶子的生命周期。可以使每个节点维护一个**到达时间戳**，每次新节点添加到树中或者通过节点查找树根的时候，都要刷新该节点本身的到达时间戳和根节点的到达时间戳，这样就可以保证当树根过期时，删除的是一整棵树（树中所有节点的到达时间不晚于树根），且不影响其他的树。
